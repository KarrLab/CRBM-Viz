import {
  Controller,
  Get,
  Logger,
  Post,
  Body,
  UseInterceptors,
  UploadedFile,
  UploadedFiles,
  Inject,
} from '@nestjs/common';
import { MessagePattern, ClientProxy } from '@nestjs/microservices';
import { ConfigService } from '@nestjs/config';
import { FileInterceptor } from '@nestjs/platform-express';
import * as fs from 'fs';
import { HpcService } from './services/hpc/hpc.service';
import { SbatchService } from './services/sbatch/sbatch.service';
import { SimulationDispatchSpec } from '@biosimulations/dispatch/datamodel';
import { v4 as uuid } from 'uuid';
import path from 'path';
import * as csv2Json from 'csv2json';

@Controller()
export class AppController {
  constructor(
    private readonly configService: ConfigService,
    private hpcService: HpcService,
    private sbatchService: SbatchService,
    @Inject('DISPATCH_MQ') private messageClient: ClientProxy
  ) {}
  private logger = new Logger(AppController.name);

  @MessagePattern('dispatch')
  uploadFile(data: SimulationDispatchSpec) {
    this.logger.log('Data received: ' + JSON.stringify(data));
    // TODO: Replace with fileStorage URL from configModule (BiosimulationsConfig)
    const fileStorage = process.env.FILE_STORAGE;
    const sbatchStorage = `${fileStorage}/SBATCH/ID`;

    if (
      data.simulator !== 'COPASI' &&
      data.simulator !== 'VCell' &&
      data.simulator !== 'Tellurium' &&
      data.simulator !== 'CopraPy' &&
      data.simulator !== 'BioNetGen'
    ) {
      return { message: 'Unsupported simulator was provided!' };
    }

    const omexPath = data.filepathOnDataStore;
    const sbatchName = `${uuid()}.sbatch`;
    const sbatchPath = path.join(sbatchStorage, sbatchName);

    this.logger.log('SBatch path: ' + sbatchPath);

    // Generate SBATCH script
    const simulatorString = `biosimulations_${data.simulator.toLowerCase()}_${
      data.simulatorVersion
    }`;
    const hpcTempDirPath = `${this.configService.get('hpc').simDirBase}/${
      data.uniqueFilename.split('.')[0]
    }`;
    const sbatchString = this.sbatchService.generateSbatch(
      hpcTempDirPath,
      simulatorString,
      data.filename
    );
    fs.writeFileSync(sbatchPath, sbatchString);

    this.logger.log('HPC Temp basedir: ' + hpcTempDirPath);

    this.hpcService.dispatchJob(
      hpcTempDirPath,
      sbatchPath,
      omexPath,
      data.filename
    );

    return { message: 'Simulation dispatch started.' };
  }

  @MessagePattern('dispatch_log')
  async dispatchLog(data: any) {
    const fileStorage = process.env.FILE_STORAGE || '';
    const simDirSplit = data['simDir'].split('/');
    const uuid = simDirSplit[simDirSplit.length - 1];
    const resDir = path.join(fileStorage, 'simulations', uuid, 'out');
    
    this.logger.log('Log message data: ' + JSON.stringify(data));
    this.logger.log('Output directory: ' + resDir);

    // parse JobID from data
    const slurmjobId = data['hpcOutput']['stdout'].match(/\d+/)[0];
    this.logger.log('JobId: ' + JSON.stringify(slurmjobId));

    // Get initial status of jub running
    const squeueRes: any = await this.hpcService.squeueStatus(slurmjobId);
    const jobMatch = squeueRes['stdout'].match(/\d+/);
    let isJobRunning: boolean = jobMatch !== null && jobMatch[0] === slurmjobId;

    // Checking the job running or not
    while (isJobRunning) {
      this.logger.log('Job is running');
      const squeueRes: any = await this.hpcService.squeueStatus(slurmjobId);
      const jobMatch = squeueRes['stdout'].match(/\d+/);
      isJobRunning = jobMatch !== null && jobMatch[0] === slurmjobId;
    }
    this.logger.log('Job stopped running');

    // Convert CSV to JSON

    // const resDir = path.join(
    //   '/Users/akhilteja/sharedFiles/simulations/eb36618b-38e7-4146-bd30-410823c1f22e',
    //   'out'
    // );
    
    const directoryList = fs.readdirSync(resDir);

    // NOTE: job.output is the Log file generated by the SBATCH simulation job
    const logFileIndex = directoryList.indexOf('job.output');
    directoryList.splice(logFileIndex);

    directoryList.forEach((directoryName: string) => {
      const fileList = fs.readdirSync(path.join(resDir, directoryName));

      fileList.forEach(async (filename: string) => {
        if (filename.endsWith('csv')) {
          const filePath = path.join(resDir, directoryName, filename);
          this.logger.log('Reading file: ' + filePath);

          const jsonPath = filePath.split('.csv')[0] + '.json';

          fs.createReadStream(filePath)
              .pipe(
                csv2Json.default({
                  separator: ',',
                })
              )
              .pipe(fs.createWriteStream(jsonPath))
              .on('close', () => {
                // Convert CSV to chart JSON
                const chartJsonPath = jsonPath.split('.json')[0] + '_chart.json';
                const jsonData = fs.readFileSync(jsonPath).toString();

                const chartResults = this.convertJsonDataToChartData(JSON.parse(jsonData));
                fs.writeFileSync(chartJsonPath, JSON.stringify(chartResults));
              });
        }
      });
    });

  }

  convertJsonDataToChartData(data: any) {
   
   const finalRes: any = {};

    const taskKeys = Object.keys(data[0]);
    taskKeys.splice(taskKeys.indexOf('time'), 1);

    for (const taskKey of taskKeys) {
      finalRes[taskKey] = {};
      finalRes[taskKey]['x'] = [];
      finalRes[taskKey]['y'] = [];
      finalRes[taskKey]['type'] = 'scatter';
    }

    for (const dataObj of data) {
      for (const taskKey of taskKeys) {
        finalRes[taskKey]['x'].push(dataObj['time']);
        finalRes[taskKey]['y'].push(dataObj[taskKey]);
      }
    }

    return finalRes;
  }
}
